{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------Team 48------------\n",
    "| Name          | Student ID |\n",
    "|---------------|------------|\n",
    "| Yifei ZHANG   | 1174267    |\n",
    "| Yibo HUANG    | 1380231    |\n",
    "| Hanzhang SUN  | 1379790    |\n",
    "| Liyang CHEN   | 1135879    |\n",
    "| Yueyang WU    | 1345511    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def print_metadata_details(metadata):\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        if isinstance(value, dict):  #if the value is a dictionary, keep iterating the subkeys and subvalues\n",
    "            for subkey, subvalue in value.items():\n",
    "                print(f\"  {subkey}: {subvalue}\")\n",
    "        else:\n",
    "            print(f\"Value: {value}\")\n",
    "        print()  #print a space for better formatting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#load the meta data\n",
    "with open('PM2003-2007-meta.json', 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "#check the details of the data\n",
    "print_metadata_details(metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#load the meta data\n",
    "with open('PM2008-2012-meta.json', 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "#check the details of the data\n",
    "print_metadata_details(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#load the meta data\n",
    "with open('PM2010-2014-meta.json', 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "#check the details of the data\n",
    "print_metadata_details(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#load the meta data\n",
    "with open('PM2011-2015-meta.json', 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "#check the details of the data\n",
    "print_metadata_details(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#load the meta data\n",
    "with open('PM2014-2018-meta.json', 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "#check the details of the data\n",
    "print_metadata_details(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('PM2008-2012-meta.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['organisation', 'name', 'title', 'legal', 'referenceSystemIdentifier', 'geoLevel', 'key', 'keyRegex', 'availability', 'geomField', 'keyword', 'theme', 'temporalExtent', 'type', '_id', 'bbox', 'abstract', 'selectedAttributes', 'filter'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area_code\n"
     ]
    }
   ],
   "source": [
    "feature = data.get('filter', {}).get('feature', {})\n",
    "print(feature.get('key'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filterType': 'tabular', 'feature': {'key': 'area_code', 'geoLevel': 'lga2011', 'geoField': 'ignored', 'year': '2006', 'featureBbox': [140.961681984, -39.159189527500004, 149.976679008, -33.9806475865], 'featureType': 'ste', 'featureInstance': '2', 'featureName': 'Victoria', 'referenceSystemIdentifier': 'urn:x-ogc:def:crs:EPSG:4283', 'prefix': '', 'keyTransform': None}, 'states': ['2']}\n"
     ]
    }
   ],
   "source": [
    "print(data['filter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'area_code', 'geoLevel': 'lga2011', 'geoField': 'ignored', 'year': '2006', 'featureBbox': [140.961681984, -39.159189527500004, 149.976679008, -33.9806475865], 'featureType': 'ste', 'featureInstance': '2', 'featureName': 'Victoria', 'referenceSystemIdentifier': 'urn:x-ogc:def:crs:EPSG:4283', 'prefix': '', 'keyTransform': None}\n"
     ]
    }
   ],
   "source": [
    "feature = data['filter']['feature']\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def check_json_structure(file_paths):\n",
    "    #store the data structure for every file\n",
    "    structure_dict = {}\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            #retrieve the keys and subkeys\n",
    "            keys = set(data.keys())\n",
    "            subkeys = set()\n",
    "            for key in data:\n",
    "                if isinstance(data[key], dict):\n",
    "                    subkeys.update(data[key].keys())\n",
    "            \n",
    "            #add the path and structures to dictionary\n",
    "            structure_dict[file_path] = (keys, subkeys)\n",
    "    \n",
    "    return structure_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve all files' paths from the folder\n",
    "meta_data_path = '/Users/yueyangwu/Desktop/sorted_newData(Disease)/PM_meta/'\n",
    "file_paths = [os.path.join(meta_data_path, file) for file in os.listdir(meta_data_path) if file.endswith('.json')]\n",
    "\n",
    "#check the structure\n",
    "structure_dict = check_json_structure(file_paths)\n",
    "\n",
    "#output:\n",
    "for file_path, structure in structure_dict.items():\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Keys: {structure[0]}\")\n",
    "    print(f\"Subkeys: {structure[1]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the PM_meta To a New Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_json_to_df(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    def flatten_dict(d, parent_key=''):\n",
    "        for k, v in d.items():\n",
    "            new_key = parent_key + '_' + k if parent_key else k\n",
    "            if isinstance(v, dict):\n",
    "                flatten_dict(v, new_key)\n",
    "            else:\n",
    "                records.append({new_key: v})\n",
    "    \n",
    "    flatten_dict(data)\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the path to the meta file\n",
    "meta_data_path = '/Users/yueyangwu/Desktop/sorted_newData(Disease)/PM_meta/'\n",
    "\n",
    "#retrieve all files' paths from the folder\n",
    "file_paths = [os.path.join(meta_data_path, file) for file in os.listdir(meta_data_path) if file.endswith('.json')]\n",
    "\n",
    "#load all jsons and make them to be dataframes\n",
    "df_list = [load_json_to_df(file_path) for file_path in file_paths]\n",
    "\n",
    "#merge all dataframes\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "#save all merged dataframe as json\n",
    "combined_df.to_json('PM_meta_combined_0.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df['keyRegex'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read merged dataFrame\n",
    "combined_df = pd.read_json('PM_meta_combined_0.json', orient='records')\n",
    "\n",
    "#transfer combined_df as a format of nested dictionary list\n",
    "nested_data = []\n",
    "for lga_code, lga_group in combined_df.groupby('filter_feature_key'):\n",
    "    lga_dict = {'lga_code': lga_code, 'lga_name': f'LGA {lga_code}', 'years': []}\n",
    "    for year, year_group in lga_group.groupby('year'):\n",
    "        year_dict = {'year': year, 'diseases': []}\n",
    "        for disease, disease_group in year_group.groupby('disease'):\n",
    "            disease_dict = {\n",
    "                'disease_name': disease,\n",
    "                'asr': disease_group['ASR'].iloc[0],\n",
    "                'sr': disease_group['SR'].iloc[0],\n",
    "                'number': disease_group['count'].iloc[0]\n",
    "            }\n",
    "            year_dict['diseases'].append(disease_dict)\n",
    "        lga_dict['years'].append(year_dict)\n",
    "    nested_data.append(lga_dict)\n",
    "\n",
    "#write the nested dictionary list to json format and save\n",
    "with open('pm_meta_combined_1.json', 'w') as json_file:\n",
    "    json.dump(nested_data, json_file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
